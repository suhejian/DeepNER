{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hejiansu/anaconda3/envs/deepner/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from tools.data_utils import get_unique_tags\n",
    "from tools.data import SequenceLabelingDataset, collate_fn, PredSequenceLabelingDataset, pred_collate_fn\n",
    "from tools.data_utils import read_data\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "from train_and_eval import Trainer\n",
    "import torch\n",
    "from tools.utils import get_logger\n",
    "from config import Config\n",
    "\n",
    "\n",
    "def load_data(opt):\n",
    "    \"\"\"\n",
    "    根据设置的参数加载数据\n",
    "    包括得到标签信息(如映射等)和dataset以及dataloader\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # 加载数据\n",
    "    train_data, dev_data, test_data = read_data(opt.data_dir)\n",
    "\n",
    "    # 得到标签相关信息, 一方面为了将标签转换为索引, 另一方面为BERT初始化时使用\n",
    "    unique_tags, labels_to_ids, ids_to_labels = get_unique_tags(train_data)\n",
    "    opt.unique_tags = unique_tags\n",
    "    opt.labels_to_ids = labels_to_ids\n",
    "    opt.ids_to_labels = ids_to_labels\n",
    "\n",
    "    train_dataset = SequenceLabelingDataset(data=train_data, labels_to_ids=labels_to_ids, tokenizer=opt.tokenizer, max_length=opt.max_length)\n",
    "    dev_dataset = SequenceLabelingDataset(data=dev_data, labels_to_ids=labels_to_ids, tokenizer=opt.tokenizer, max_length=opt.max_length)\n",
    "    test_dataset = PredSequenceLabelingDataset(data=test_data, tokenizer=opt.tokenizer, max_length=opt.max_length)\n",
    "    \n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler, collate_fn=collate_fn)\n",
    "\n",
    "    dev_sampler = SequentialSampler(dev_dataset)\n",
    "    dev_dataloader = DataLoader(dev_dataset, batch_size=32, sampler=dev_sampler, collate_fn=collate_fn)\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, sampler=dev_sampler, collate_fn=pred_collate_fn)\n",
    "\n",
    "    return train_dataloader, dev_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Config()\n",
    "logger = get_logger(opt.log_path)\n",
    "opt.logger = logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 09:55:11 - INFO: 开始加载数据\n",
      "2022-07-10 09:55:11 - INFO: 加载数据完成\n",
      "2022-07-10 09:55:11 - INFO: 标签信息: {'B-address': 0, 'B-book': 1, 'B-company': 2, 'B-game': 3, 'B-government': 4, 'B-movie': 5, 'B-name': 6, 'B-organization': 7, 'B-position': 8, 'B-scene': 9, 'I-address': 10, 'I-book': 11, 'I-company': 12, 'I-game': 13, 'I-government': 14, 'I-movie': 15, 'I-name': 16, 'I-organization': 17, 'I-position': 18, 'I-scene': 19, 'O': 20}\n"
     ]
    }
   ],
   "source": [
    "# tokenizer用于处理文本\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "opt.tokenizer = tokenizer\n",
    "\n",
    "# 加载数据\n",
    "opt.logger.info(\"开始加载数据\")\n",
    "train_dataloader, dev_dataloader, test_dataloader = load_data(opt)\n",
    "opt.logger.info(\"加载数据完成\")\n",
    "opt.logger.info(f\"标签信息: {opt.labels_to_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/hejiansu/anaconda3/envs/deepner/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 模型\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-chinese\", num_labels=len(opt.unique_tags))\n",
    "# 设置设备, 数据已经移动到config中设置的设备上\n",
    "# 因此需要将模型也移动到相同设备上\n",
    "model = model.to(opt.device)\n",
    "# 模型训练\n",
    "trainer = Trainer(model=model, opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1724, 2335,  ..., 5865,  868,  511],\n",
      "        [ 101, 2225, 3189,  ...,    0,    0,    0],\n",
      "        [ 101, 7218, 1545,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  100,  157,  ...,    0,    0,    0],\n",
      "        [ 101,  517, 4868,  ...,    0,    0,    0],\n",
      "        [ 101,  123,  121,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'sent_length': tensor([48, 31, 17, 21, 40, 26, 15, 49, 44, 46, 26, 41, 49, 45, 37, 45, 36, 49,\n",
      "        22, 40, 48,  8, 11, 21, 45, 47, 37, 42, 49, 25, 43, 38])}\n"
     ]
    }
   ],
   "source": [
    "for batch in test_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 09:55:43 - INFO: Start Predicting...\n",
      "Predicting: 100%|██████████| 42/42 [00:02<00:00, 17.63it/s]\n",
      "2022-07-10 09:55:46 - INFO: Predicting Done.\n",
      "2022-07-10 09:55:46 - INFO: Predict result save to ./predict_results/predict.txt\n"
     ]
    }
   ],
   "source": [
    "pred_result = trainer.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deepner')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d3606aff3b8fd843f97c2a6e4db0e19b5f072918cfeac50ebc31dfdde5de028"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
